---
phase: 08-backend-provider-foundation
plan: 03
type: execute
wave: 2
depends_on: ["08-01", "08-02"]
files_modified:
  - src/caal/llm/providers/__init__.py
autonomous: true

must_haves:
  truths:
    - "create_provider('openai_compatible', ...) returns OpenAICompatibleProvider instance"
    - "create_provider('openrouter', ...) returns OpenRouterProvider instance"
    - "create_provider_from_settings() builds both new provider types from settings dict"
    - "Both new providers are exported from the package"
  artifacts:
    - path: "src/caal/llm/providers/__init__.py"
      provides: "Factory functions with new provider support"
      exports: ["OpenAICompatibleProvider", "OpenRouterProvider", "create_provider", "create_provider_from_settings"]
  key_links:
    - from: "src/caal/llm/providers/__init__.py"
      to: "src/caal/llm/providers/openai_compatible_provider.py"
      via: "imports OpenAICompatibleProvider"
      pattern: "from \\.openai_compatible_provider import OpenAICompatibleProvider"
    - from: "src/caal/llm/providers/__init__.py"
      to: "src/caal/llm/providers/openrouter_provider.py"
      via: "imports OpenRouterProvider"
      pattern: "from \\.openrouter_provider import OpenRouterProvider"
---

<objective>
Integrate both new providers into the factory functions so they can be instantiated from settings.

Purpose: Enable the CAAL agent to create OpenAI-compatible and OpenRouter providers using the same factory pattern as existing providers.
Output: Updated `__init__.py` with exports and factory function support for both new providers.
</objective>

<execution_context>
@/Users/mmaudet/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mmaudet/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md

# Prior plan outputs (needed for understanding what was created)
@.planning/phases/08-backend-provider-foundation/08-01-SUMMARY.md
@.planning/phases/08-backend-provider-foundation/08-02-SUMMARY.md

# File to modify
@src/caal/llm/providers/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add new provider imports and exports</name>
  <files>src/caal/llm/providers/__init__.py</files>
  <action>
Update `src/caal/llm/providers/__init__.py` to import and export the new providers:

1. **Add imports** after existing provider imports:
   ```python
   from .openai_compatible_provider import OpenAICompatibleProvider
   from .openrouter_provider import OpenRouterProvider
   ```

2. **Update __all__** to include new providers:
   ```python
   __all__ = [
       "LLMProvider",
       "LLMResponse",
       "ToolCall",
       "OllamaProvider",
       "GroqProvider",
       "OpenAICompatibleProvider",
       "OpenRouterProvider",
       "create_provider",
   ]
   ```

3. **Update module docstring** to list new providers:
   ```python
   """LLM provider implementations for CAAL.

   Providers:
       - OllamaProvider: Local Ollama with think parameter support
       - GroqProvider: Groq cloud API
       - OpenAICompatibleProvider: Any OpenAI-compatible server
       - OpenRouterProvider: OpenRouter cloud API (400+ models)
   ...
   """
   ```
  </action>
  <verify>
```bash
uv run python -c "from caal.llm.providers import OpenAICompatibleProvider, OpenRouterProvider; print('Imports OK')"
```
Should output: `Imports OK`
  </verify>
  <done>
- Both new providers are imported in __init__.py
- Both new providers are listed in __all__
- Module docstring updated
  </done>
</task>

<task type="auto">
  <name>Task 2: Update create_provider factory function</name>
  <files>src/caal/llm/providers/__init__.py</files>
  <action>
Update the `create_provider()` function to support new provider names:

1. **Add cases** in the if/elif chain:
   ```python
   elif provider_name == "openai_compatible":
       return OpenAICompatibleProvider(**kwargs)
   elif provider_name == "openrouter":
       return OpenRouterProvider(**kwargs)
   ```

2. **Update error message** to list all supported providers:
   ```python
   raise ValueError(
       f"Unknown LLM provider: {provider_name}. "
       f"Supported providers: ollama, groq, openai_compatible, openrouter"
   )
   ```

3. **Update docstring** to document new providers in the example.
  </action>
  <verify>
```bash
uv run python -c "
from caal.llm.providers import create_provider

# Test OpenAI-compatible
p1 = create_provider('openai_compatible', model='test', base_url='http://localhost:8000/v1')
print(f'OpenAI-compatible: {p1.provider_name}')

# Test OpenRouter
p2 = create_provider('openrouter', model='openai/gpt-4', api_key='test-key')
print(f'OpenRouter: {p2.provider_name}')

print('Factory OK')
"
```
Should output:
```
OpenAI-compatible: openai_compatible
OpenRouter: openrouter
Factory OK
```
  </verify>
  <done>
- create_provider('openai_compatible', ...) works
- create_provider('openrouter', ...) works
- Error message lists all four providers
  </done>
</task>

<task type="auto">
  <name>Task 3: Update create_provider_from_settings factory</name>
  <files>src/caal/llm/providers/__init__.py</files>
  <action>
Update the `create_provider_from_settings()` function to handle new providers:

1. **Add cases** for new providers. Settings keys follow the pattern established by existing providers:

   For openai_compatible:
   ```python
   elif provider_name == "openai_compatible":
       api_key = settings.get("openai_api_key") or os.environ.get("OPENAI_API_KEY")
       return OpenAICompatibleProvider(
           model=settings.get("openai_model", "gpt-3.5-turbo"),
           base_url=settings.get("openai_base_url", "http://localhost:8000/v1"),
           api_key=api_key,
           temperature=settings.get("temperature", 0.7),
       )
   ```

   For openrouter:
   ```python
   elif provider_name == "openrouter":
       api_key = settings.get("openrouter_api_key") or os.environ.get("OPENROUTER_API_KEY")
       if not api_key:
           raise ValueError(
               "OpenRouter API key required. Set openrouter_api_key in settings "
               "or OPENROUTER_API_KEY environment variable."
           )
       return OpenRouterProvider(
           model=settings.get("openrouter_model", "openai/gpt-4"),
           api_key=api_key,
           temperature=settings.get("temperature", 0.7),
       )
   ```

2. **Update error message** to list all supported providers.

3. **Update docstring** to document new settings keys:
   - openai_api_key, openai_base_url, openai_model (for openai_compatible)
   - openrouter_api_key, openrouter_model (for openrouter)
  </action>
  <verify>
```bash
uv run python -c "
from caal.llm.providers import create_provider_from_settings

# Test OpenAI-compatible from settings
settings1 = {
    'llm_provider': 'openai_compatible',
    'openai_model': 'mistral',
    'openai_base_url': 'http://localhost:8080/v1',
}
p1 = create_provider_from_settings(settings1)
print(f'From settings (openai_compatible): {p1.provider_name}, model={p1.model}')

# Test OpenRouter from settings
settings2 = {
    'llm_provider': 'openrouter',
    'openrouter_model': 'anthropic/claude-3-opus',
    'openrouter_api_key': 'test-key',
}
p2 = create_provider_from_settings(settings2)
print(f'From settings (openrouter): {p2.provider_name}, model={p2.model}')

print('Settings factory OK')
"
```
Should output:
```
From settings (openai_compatible): openai_compatible, model=mistral
From settings (openrouter): openrouter, model=anthropic/claude-3-opus
Settings factory OK
```
  </verify>
  <done>
- create_provider_from_settings() handles llm_provider="openai_compatible"
- create_provider_from_settings() handles llm_provider="openrouter"
- Settings keys follow established pattern (provider_api_key, provider_model, etc.)
- OpenRouter validates API key is present
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Type checking passes: `uv run mypy src/caal/llm/providers/__init__.py`
2. Linting passes: `uv run ruff check src/caal/llm/providers/__init__.py`
3. All providers importable from package: `from caal.llm.providers import OpenAICompatibleProvider, OpenRouterProvider`
4. Factory functions work for all four providers
5. Settings factory reads correct keys for new providers
</verification>

<success_criteria>
- Both new providers exported from caal.llm.providers
- create_provider() supports "openai_compatible" and "openrouter"
- create_provider_from_settings() supports both new providers with appropriate settings keys
- Type safe (mypy passes)
- Style compliant (ruff passes)
- Phase 8 success criteria met: Provider factory creates OpenAI-compatible and OpenRouter instances from settings
</success_criteria>

<output>
After completion, create `.planning/phases/08-backend-provider-foundation/08-03-SUMMARY.md`
</output>
