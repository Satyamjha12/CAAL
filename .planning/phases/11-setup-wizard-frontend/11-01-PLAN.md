---
phase: 11-setup-wizard-frontend
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - frontend/components/setup/setup-wizard.tsx
  - frontend/components/setup/provider-step.tsx
  - frontend/messages/en.json
  - frontend/messages/fr.json
  - frontend/messages/it.json
autonomous: true

must_haves:
  truths:
    - "Setup wizard displays OpenAI-compatible as a provider choice"
    - "Setup wizard displays OpenRouter as a provider choice"
    - "OpenAI-compatible form shows base URL, optional API key, and model selection after test"
    - "OpenRouter form shows API key and model selection after test"
    - "Test button validates connection before models are shown"
    - "Failed tests show error message"
    - "Continue button disabled until provider is fully configured"
  artifacts:
    - path: "frontend/components/setup/setup-wizard.tsx"
      provides: "Extended SetupData interface and INITIAL_DATA, updated canProceed"
      contains: "openai_compatible.*openrouter"
    - path: "frontend/components/setup/provider-step.tsx"
      provides: "4-provider grid, form sections, test functions"
      contains: "testOpenAICompatible.*testOpenRouter"
    - path: "frontend/messages/en.json"
      provides: "English translations for new providers"
      contains: "openaiCompatibleDesc"
    - path: "frontend/messages/fr.json"
      provides: "French translations for new providers"
      contains: "openaiCompatibleDesc"
    - path: "frontend/messages/it.json"
      provides: "Italian translations for new providers"
      contains: "openaiCompatibleDesc"
  key_links:
    - from: "frontend/components/setup/provider-step.tsx"
      to: "/api/setup/test-openai-compatible"
      via: "fetch in testOpenAICompatible"
      pattern: "fetch.*api/setup/test-openai-compatible"
    - from: "frontend/components/setup/provider-step.tsx"
      to: "/api/setup/test-openrouter"
      via: "fetch in testOpenRouter"
      pattern: "fetch.*api/setup/test-openrouter"
    - from: "frontend/components/setup/setup-wizard.tsx"
      to: "frontend/components/setup/provider-step.tsx"
      via: "SetupData type import"
      pattern: "import.*SetupData"
---

<objective>
Add OpenAI-compatible and OpenRouter as provider choices in the setup wizard with connection testing and model selection.

Purpose: First-run users can configure the two new LLM providers alongside Ollama and Groq
Output: Extended setup wizard with 4-provider grid, test buttons, form sections, and i18n support
</objective>

<execution_context>
@/Users/mmaudet/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mmaudet/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/11-setup-wizard-frontend/11-RESEARCH.md

# Source files to modify
@frontend/components/setup/setup-wizard.tsx
@frontend/components/setup/provider-step.tsx
@frontend/messages/en.json
@frontend/messages/fr.json
@frontend/messages/it.json

# Reference patterns (Phase 10 endpoints already exist)
@frontend/app/api/setup/test-openai-compatible/route.ts
@frontend/app/api/setup/test-openrouter/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend SetupData interface and canProceed validation</name>
  <files>frontend/components/setup/setup-wizard.tsx</files>
  <action>
Update the SetupData interface and related code in setup-wizard.tsx:

1. Extend `SetupData` interface with new LLM provider type and fields:
   - Change `llm_provider` union to: `'ollama' | 'groq' | 'openai_compatible' | 'openrouter'`
   - Add `openai_base_url: string`
   - Add `openai_api_key: string`
   - Add `openai_model: string`
   - Add `openrouter_api_key: string`
   - Add `openrouter_model: string`

2. Update `INITIAL_DATA` constant with empty string defaults for all new fields:
   - `openai_base_url: ''`
   - `openai_api_key: ''`
   - `openai_model: ''`
   - `openrouter_api_key: ''`
   - `openrouter_model: ''`

3. Update `canProceed()` function to handle new providers:
   - For `openai_compatible`: return `data.openai_base_url && data.openai_model`
   - For `openrouter`: return `data.openrouter_api_key && data.openrouter_model`

Follow existing patterns exactly. The canProceed check for openai_compatible requires base_url but NOT api_key (api_key is optional for local servers).
  </action>
  <verify>TypeScript compiles without errors: `cd frontend && pnpm build`</verify>
  <done>SetupData includes all 5 new fields, INITIAL_DATA has matching defaults, canProceed validates new providers correctly</done>
</task>

<task type="auto">
  <name>Task 2: Add provider grid and form sections with test functions</name>
  <files>frontend/components/setup/provider-step.tsx</files>
  <action>
Extend provider-step.tsx to support OpenAI-compatible and OpenRouter:

1. Add state for new provider models (following existing ollamaModels/groqModels pattern):
   - `const [openaiModels, setOpenaiModels] = useState<string[]>([]);`
   - `const [openrouterModels, setOpenrouterModels] = useState<string[]>([]);`

2. Add testOpenAICompatible function (following testOllama pattern):
   ```tsx
   const testOpenAICompatible = useCallback(async () => {
     if (!data.openai_base_url) return;
     setTestStatus('testing');
     setTestError(null);
     try {
       const response = await fetch('/api/setup/test-openai-compatible', {
         method: 'POST',
         headers: { 'Content-Type': 'application/json' },
         body: JSON.stringify({
           base_url: data.openai_base_url,
           api_key: data.openai_api_key,  // May be empty
         }),
       });
       const result = await response.json();
       if (result.success) {
         setTestStatus('success');
         setOpenaiModels(result.models || []);
         if (!data.openai_model && result.models?.length > 0) {
           updateData({ openai_model: result.models[0] });
         }
       } else {
         setTestStatus('error');
         setTestError(result.error || 'Connection failed');
       }
     } catch {
       setTestStatus('error');
       setTestError('Failed to connect');
     }
   }, [data.openai_base_url, data.openai_api_key, data.openai_model, updateData]);
   ```

3. Add testOpenRouter function (following testGroq pattern):
   ```tsx
   const testOpenRouter = useCallback(async () => {
     if (!data.openrouter_api_key) return;
     setTestStatus('testing');
     setTestError(null);
     try {
       const response = await fetch('/api/setup/test-openrouter', {
         method: 'POST',
         headers: { 'Content-Type': 'application/json' },
         body: JSON.stringify({ api_key: data.openrouter_api_key }),
       });
       const result = await response.json();
       if (result.success) {
         setTestStatus('success');
         setOpenrouterModels(result.models || []);
         if (!data.openrouter_model && result.models?.length > 0) {
           updateData({ openrouter_model: result.models[0] });
         }
       } else {
         setTestStatus('error');
         setTestError(result.error || 'Invalid API key');
       }
     } catch {
       setTestStatus('error');
       setTestError('Failed to validate');
     }
   }, [data.openrouter_api_key, data.openrouter_model, updateData]);
   ```

4. Expand provider grid from 2 columns to 4 buttons in 2x2 layout:
   - Keep existing grid-cols-2 class
   - Add OpenAI Compatible button after Groq (uses t('openaiCompatibleDesc'))
   - Add OpenRouter button after OpenAI Compatible (uses t('openrouterDesc'))

5. Add OpenAI-compatible form section (when `data.llm_provider === 'openai_compatible'`):
   - Base URL input (required) with Test button
   - API key input (optional, type="password") with helper text t('openaiApiKeyNote')
   - Model select dropdown (shown after successful test, if models.length > 0)
   - Success/error status messages (same pattern as Ollama)
   - STT note: t('openaiCompatibleSttNote')

6. Add OpenRouter form section (when `data.llm_provider === 'openrouter'`):
   - API key input (required, type="password") with Test button
   - Link to openrouter.ai/keys for getting API key (same pattern as Groq)
   - Model select dropdown (shown after successful test)
   - Success/error status messages (same pattern as Groq)
   - STT note: t('openrouterSttNote')

Use EXACT styling from existing Ollama/Groq sections. Copy the CSS classes verbatim.
  </action>
  <verify>TypeScript compiles: `cd frontend && pnpm build`</verify>
  <done>Provider step shows 4 providers in 2x2 grid, test buttons call correct endpoints, models populate after successful test</done>
</task>

<task type="auto">
  <name>Task 3: Add i18n translations for all three languages</name>
  <files>
    frontend/messages/en.json
    frontend/messages/fr.json
    frontend/messages/it.json
  </files>
  <action>
Add new translation keys under Settings.providers for all three languages:

**English (en.json):**
```json
"openaiCompatibleDesc": "Self-hosted or OpenAI-compatible API",
"openrouterDesc": "Access 200+ models via unified API",
"baseUrl": "Base URL",
"optional": "optional",
"openaiApiKeyNote": "Leave empty if your server doesn't require authentication",
"openaiCompatibleSttNote": "Using OpenAI-compatible enables local speech-to-text via Speaches.",
"openrouterSttNote": "Using OpenRouter enables fast cloud speech-to-text via Groq Whisper."
```

**French (fr.json):**
```json
"openaiCompatibleDesc": "API auto-hebergee ou compatible OpenAI",
"openrouterDesc": "Acces a plus de 200 modeles via API unifiee",
"baseUrl": "URL de base",
"optional": "optionnel",
"openaiApiKeyNote": "Laissez vide si votre serveur ne necessite pas d'authentification",
"openaiCompatibleSttNote": "Utiliser OpenAI-compatible active la reconnaissance vocale locale via Speaches.",
"openrouterSttNote": "Utiliser OpenRouter active la reconnaissance vocale cloud rapide via Groq Whisper."
```

**Italian (it.json):**
```json
"openaiCompatibleDesc": "API self-hosted o compatibile OpenAI",
"openrouterDesc": "Accesso a oltre 200 modelli tramite API unificata",
"baseUrl": "URL di base",
"optional": "opzionale",
"openaiApiKeyNote": "Lascia vuoto se il tuo server non richiede autenticazione",
"openaiCompatibleSttNote": "Usare OpenAI-compatible attiva il riconoscimento vocale locale tramite Speaches.",
"openrouterSttNote": "Usare OpenRouter attiva il riconoscimento vocale cloud veloce tramite Groq Whisper."
```

Add these keys in the existing Settings.providers object, after the existing groqSttNote key.
  </action>
  <verify>
    - JSON syntax valid: `cd frontend && node -e "require('./messages/en.json')"` (repeat for fr.json, it.json)
    - Build succeeds: `cd frontend && pnpm build`
  </verify>
  <done>All three language files contain new provider translations with consistent keys</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. TypeScript compilation: `cd frontend && pnpm build`
2. Lint check: `cd frontend && pnpm lint`
3. JSON validity: `node -e "require('./messages/en.json'); require('./messages/fr.json'); require('./messages/it.json')"`

Manual verification (checkpoint in Phase 12):
- Setup wizard shows 4 provider options in 2x2 grid
- Selecting OpenAI Compatible shows base URL + optional API key form
- Selecting OpenRouter shows API key form
- Test buttons call correct endpoints and show success/error
- Models populate after successful test
- Continue button disabled until provider fully configured
</verification>

<success_criteria>
1. SetupData interface includes all 5 new fields with correct types
2. INITIAL_DATA has matching empty string defaults
3. Provider grid shows 4 options: Ollama, Groq, OpenAI Compatible, OpenRouter
4. OpenAI-compatible form: base URL (required), API key (optional), model select
5. OpenRouter form: API key (required), model select
6. Test functions call /api/setup/test-openai-compatible and /api/setup/test-openrouter
7. canProceed correctly validates: openai requires base_url + model, openrouter requires api_key + model
8. All translations present in EN, FR, IT
9. No TypeScript errors, lint passes
</success_criteria>

<output>
After completion, create `.planning/phases/11-setup-wizard-frontend/11-01-SUMMARY.md`
</output>
